{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot_0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"o-Fp8AzC5YKt","colab_type":"text"},"source":["# **Chatbot**\n","\n","This notebook intend to perform the creation of a simple chatbot using tensorflow api. \n","\n","This chatbot does not learn throughtout the conversation, and simply pick the best answer possible inside a json file."]},{"cell_type":"code","metadata":{"id":"VpcQWlJ46yWY","colab_type":"code","outputId":"e21c2689-d1cc-4392-8820-a68079e69eff","executionInfo":{"status":"ok","timestamp":1582075046898,"user_tz":180,"elapsed":680,"user":{"displayName":"Ayrton Casella","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDY4Y-CpAhmgK0MSgqG8WQaBCIAJsXKOzPcLPoITw=s64","userId":"06250145704132302615"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","from google.colab import files\n","import io\n","import os\n","drive.mount('/content/drive')\n","#%cd /content/drive/My Drive/Colab Notebooks\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Chatbot\")\n","#os.listdir()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bkq8GHdlk2w3","colab_type":"code","outputId":"461b76a2-8ae7-4f9c-d471-3095a0fd5e58","executionInfo":{"status":"ok","timestamp":1582075835180,"user_tz":180,"elapsed":970,"user":{"displayName":"Ayrton Casella","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDY4Y-CpAhmgK0MSgqG8WQaBCIAJsXKOzPcLPoITw=s64","userId":"06250145704132302615"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import nltk\n","nltk.download('punkt')\n","from nltk.stem.lancaster import LancasterStemmer\n","\n","import numpy as np\n","import tflearn\n","import tensorflow as tf\n","import random\n","import json\n","import pickle\n","\n","stemmer = LancasterStemmer()\n","\n","with open('intents.json', 'r') as file:\n","    data = json.load(file)\n","\n","\n","#print(data['intents'])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A1rCzTYbCQWU","colab_type":"code","colab":{}},"source":["try:\n","    with open('data.pickle', 'rb') as f:\n","        words, labels, training, output = pickle.load(f)\n","except:\n","    words  = [] # List of all the words in the vocabulary\n","    labels = [] # List of all intents\n","    docs_x = [] # List of list of words, according to the intents\n","    docs_y = [] # List of intents of each element in docs_x\n","\n","    for intent in data['intents']:\n","        for pattern in intent['patterns']:\n","            wrds = nltk.word_tokenize(pattern)\n","            words.extend(wrds)\n","            docs_x.append(wrds)\n","            docs_y.append(intent['tag'])\n","\n","            if intent['tag'] not in labels:\n","                labels.append(intent['tag'])\n","\n","    words = [w.lower() for w in words]\n","    #words = [stemmer.stem(w) for w in words if w not in '?']\n","    words = sorted(list(set(words)))\n","\n","    labels = sorted(labels)\n","\n","    training = []  # List of binary arrays, one array for each sentence.\n","    output   = []  # List of binary arrays, one array for the intent of each sentence.\n","\n","    out_empty = [0 for _ in range(len(labels))]\n","\n","    for x, doc in enumerate(docs_x):\n","        bag = []\n","\n","        wrds = [stemmer.stem(w) for w in doc]\n","\n","        for w in words:\n","            if w in wrds:\n","                bag.append(1)\n","            else:\n","                bag.append(0)\n","        \n","        output_row = out_empty[:]\n","        output_row[labels.index(docs_y[x])] = 1\n","\n","        training.append(bag)\n","        output.append(output_row)\n","    \n","    # Converting list to numpy arrays\n","    training = np.array(training)\n","    output = np.array(output)\n","\n","    with open('data.pickle', 'wb') as f:\n","        pickle.dump((words, labels, training, output), f)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5SrDFLPM7x8_","colab_type":"text"},"source":["# Defining the DNN (deep neural network), aka MLP (Multi Layer Perceptron)\n","\n","We use *tflearn* to build our model. This model has a input layer with some neurons, two hidden layers with 8 neurons each, and an output layer with 6 neurons (1 for each intent). In the output layer, it is used the softmax activation function.\n","\n","What we are doing is using the DNN to classify the sentence the user types in one of the intents on the json file, and then choose a random answer from that intent. If the output does not show a very high confidence, the answer is \"*I don't understand it, sorry :(*\""]},{"cell_type":"code","metadata":{"id":"fppdUULEGT9_","colab_type":"code","outputId":"6fd4a376-ed83-4a6b-df94-6d221a7242b2","executionInfo":{"status":"ok","timestamp":1582075877238,"user_tz":180,"elapsed":367,"user":{"displayName":"Ayrton Casella","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDY4Y-CpAhmgK0MSgqG8WQaBCIAJsXKOzPcLPoITw=s64","userId":"06250145704132302615"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["tf.reset_default_graph()\n","net = tflearn.input_data(shape=[None, len(training[0])]) # input layer\n","net = tflearn.fully_connected(net, 8)                    # hidden layer\n","net = tflearn.fully_connected(net, 8)                    # hidden layer\n","net = tflearn.fully_connected(net, len(output[0]), activation='softmax') # output layer\n","net = tflearn.regression(net)\n","\n","model = tflearn.DNN(net)\n","\n","\n","model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n","model.save('Model.tflearn')\n","print('Model was saved successfully!')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.07798\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 1000 | loss: 0.07798 - acc: 0.9542 -- iter: 24/26\n","Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.07065\u001b[0m\u001b[0m | time: 0.014s\n","| Adam | epoch: 1000 | loss: 0.07065 - acc: 0.9588 -- iter: 26/26\n","--\n","INFO:tensorflow:/content/drive/My Drive/Colab Notebooks/Chatbot/Model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n","Model was saved successfully!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cCb6eu1RGTbo","colab_type":"code","colab":{}},"source":["def bag_of_words(s, words):\n","    \"\"\" Transforms a sentence in a binary array of corresponding to which words \n","    on the vocabulary of the DNN is presented in the sentence given by the user. \n","    This array is used as input of the DNN. \"\"\"\n","\n","    bag = [0 for _ in range(len(words))]\n","\n","    s_words = nltk.word_tokenize(s)\n","    s_words = [stemmer.stem(word.lower()) for word in s_words]\n","\n","    for se in s_words:\n","        for i, w in enumerate(words):\n","            if w == se:\n","                bag[i] = 1\n","    \n","    return np.array(bag)\n","\n","def chat():\n","    \"\"\"Reads the input given by the user, process it and calculate the best answer with the DNN\"\"\"\n","\n","    print('Start talking to the chatbot!')\n","    while(True):\n","        inp = str(input('You: ')).lower()\n","        if inp in ['quit', 'bye']:\n","            print(\"Bot: See you later.\")\n","            break\n","        \n","        result = model.predict([bag_of_words(inp, words)])[0]\n","        index = np.argmax(result)\n","        tag = labels[index]\n","\n","        for tg in data['intents']:\n","            if tg['tag'] == tag:\n","                responses = tg['responses']\n","        #print(result)\n","        threshold = result[index]\n","        if threshold > 0.8:\n","            print('Bot: {}'.format(random.choice(responses)))\n","        else:\n","            print(\"Bot: I don't understand it, sorry :(\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNkOyJUSU_cP","colab_type":"code","outputId":"87893cb1-a7f9-46dc-edc8-db9d29e776d6","executionInfo":{"status":"error","timestamp":1582074260295,"user_tz":180,"elapsed":29288,"user":{"displayName":"Ayrton Casella","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDY4Y-CpAhmgK0MSgqG8WQaBCIAJsXKOzPcLPoITw=s64","userId":"06250145704132302615"}},"colab":{"base_uri":"https://localhost:8080/","height":223}},"source":["chat()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start talking to the chatbot!\n","You: Hi\n","Bot: Hi there, how can I help?\n","You: Whats your name?\n","Bot: I'm Will!\n","You: How old are you?\n","Bot: I am 26 years old!\n","You: I am leaving.\n","Bot: Sad to see you go :(\n","You: Bye.\n","Bot: Goodbye!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wamww7zVVXAA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}